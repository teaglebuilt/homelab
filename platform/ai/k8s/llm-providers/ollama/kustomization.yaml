---
apiVersion: kustomize.config.k8s.io/v1beta1
kind: Kustomization
resources:
  - backend-service.yaml
  - ollama-httproute.yaml
helmCharts:
  - name: ollama
    releaseName: ollama
    repo: https://otwld.github.io/ollama-helm/
    version: 1.14.0
    namespace: ai
    valuesInline:
      ollama:
        gpu:
          enabled: true
          type: 'nvidia'
          number: 1
        models:
          pull:
            - deepseek-coder-v2
        insecure: true

      runtimeClassName: nvidia
      nodeSelector:
        kubernetes.io/hostname: mlops-work-00
      persistentVolume:
        enabled: true
        accessModes:
          - ReadWriteOnce
      requests:
        cpu: 60m
        memory: 256Mi
        nvidia.com/gpu: 1
      limits:
        cpu: 600m
        memory: 1Gi
        nvidia.com/gpu: 1
      podSecurityContext:
        fsGroupChangePolicy: Always
        fsGroup: 1001
      containerSecurityContext:
        runAsUser: 1001
        runAsGroup: 1001
        runAsNonRoot: true
        privileged: false
        allowPrivilegeEscalation: false
        readOnlyRootFilesystem: false
        capabilities: { drop: ["ALL"] }
        seccompProfile: { type: RuntimeDefault }
